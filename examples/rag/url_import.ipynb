{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"success\",\"content\":\"# API\\n\\n## Endpoints\\n\\n- [Generate a completion](#generate-a-completion)\\n- [Generate a chat completion](#generate-a-chat-completion)\\n- [Create a Model](#create-a-model)\\n- [List Local Models](#list-local-models)\\n- [Show Model Information](#show-model-information)\\n- [Copy a Model](#copy-a-model)\\n- [Delete a Model](#delete-a-model)\\n- [Pull a Model](#pull-a-model)\\n- [Push a Model](#push-a-model)\\n- [Generate Embeddings](#generate-embeddings)\\n\\n## Conventions\\n\\n### Model names\\n\\nModel names follow a `model:tag` format, where `model` can have an optional namespace such as `example/model`. Some examples are `orca-mini:3b-q4_1` and `llama3:70b`. The tag is optional and, if not provided, will default to `latest`. The tag is used to identify a specific version.\\n\\n### Durations\\n\\nAll durations are returned in nanoseconds.\\n\\n### Streaming responses\\n\\nCertain endpoints stream responses as JSON objects and can optional return non-streamed responses.\\n\\n## Generate a completion\\n\\n```shell\\nPOST /api/generate\\n```\\n\\nGenerate a response for a given prompt with a provided model. This is a streaming endpoint, so there will be a series of responses. The final response object will include statistics and additional data from the request.\\n\\n### Parameters\\n\\n- `model`: (required) the [model name](#model-names)\\n- `prompt`: the prompt to generate a response for\\n- `images`: (optional) a list of base64-encoded images (for multimodal models such as `llava`)\\n\\nAdvanced parameters (optional):\\n\\n- `format`: the format to return a response in. Currently the only accepted value is `json`\\n- `options`: additional model parameters listed in the documentation for the [Modelfile](./modelfile.md#valid-parameters-and-values) such as `temperature`\\n- `system`: system message to (overrides what is defined in the `Modelfile`)\\n- `template`: the prompt template to use (overrides what is defined in the `Modelfile`)\\n- `context`: the context parameter returned from a previous request to `/generate`, this can be used to keep a short conversational memory\\n- `stream`: if `false` the response will be returned as a single response object, rather than a stream of objects\\n- `raw`: if `true` no formatting will be applied to the prompt. You may choose to use the `raw` parameter if you are specifying a full templated prompt in your request to the API\\n- `keep_alive`: controls how long the model will stay loaded into memory following the request (default: `5m`)\\n\\n#### JSON mode\\n\\nEnable JSON mode by setting the `format` parameter to `json`. This will structure the response as a valid JSON object. See the JSON mode [example](#request-json-mode) below.\\n\\n> Note: it's important to instruct the model to use JSON in the `prompt`. Otherwise, the model may generate large amounts whitespace.\\n\\n### Examples\\n\\n#### Generate request (Streaming)\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\"\\n}'\\n```\\n\\n##### Response\\n\\nA stream of JSON objects is returned:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T08:52:19.385406455-07:00\\\",\\n  \\\"response\\\": \\\"The\\\",\\n  \\\"done\\\": false\\n}\\n```\\n\\nThe final response in the stream also includes additional data about the generation:\\n\\n- `total_duration`: time spent generating the response\\n- `load_duration`: time spent in nanoseconds loading the model\\n- `prompt_eval_count`: number of tokens in the prompt\\n- `prompt_eval_duration`: time spent in nanoseconds evaluating the prompt\\n- `eval_count`: number of tokens in the response\\n- `eval_duration`: time in nanoseconds spent generating the response\\n- `context`: an encoding of the conversation used in this response, this can be sent in the next request to keep a conversational memory\\n- `response`: empty if the response was streamed, if not streamed, this will contain the full response\\n\\nTo calculate how fast the response is generated in tokens per second (token/s), divide `eval_count` / `eval_duration` * `10^9`.\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T19:22:45.499127Z\\\",\\n  \\\"response\\\": \\\"\\\",\\n  \\\"done\\\": true,\\n  \\\"context\\\": [1, 2, 3],\\n  \\\"total_duration\\\": 10706818083,\\n  \\\"load_duration\\\": 6338219291,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 130079000,\\n  \\\"eval_count\\\": 259,\\n  \\\"eval_duration\\\": 4232710000\\n}\\n```\\n\\n#### Request (No streaming)\\n\\n##### Request\\n\\nA response can be received in one reply when streaming is off.\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\",\\n  \\\"stream\\\": false\\n}'\\n```\\n\\n##### Response\\n\\nIf `stream` is set to `false`, the response will be a single JSON object:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T19:22:45.499127Z\\\",\\n  \\\"response\\\": \\\"The sky is blue because it is the color of the sky.\\\",\\n  \\\"done\\\": true,\\n  \\\"context\\\": [1, 2, 3],\\n  \\\"total_duration\\\": 5043500667,\\n  \\\"load_duration\\\": 5025959,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 325953000,\\n  \\\"eval_count\\\": 290,\\n  \\\"eval_duration\\\": 4709213000\\n}\\n```\\n\\n#### Request (JSON mode)\\n\\n> When `format` is set to `json`, the output will always be a well-formed JSON object. It's important to also instruct the model to respond in JSON.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"prompt\\\": \\\"What color is the sky at different times of the day? Respond using JSON\\\",\\n  \\\"format\\\": \\\"json\\\",\\n  \\\"stream\\\": false\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-11-09T21:07:55.186497Z\\\",\\n  \\\"response\\\": \\\"{\\\\n\\\\\\\"morning\\\\\\\": {\\\\n\\\\\\\"color\\\\\\\": \\\\\\\"blue\\\\\\\"\\\\n},\\\\n\\\\\\\"noon\\\\\\\": {\\\\n\\\\\\\"color\\\\\\\": \\\\\\\"blue-gray\\\\\\\"\\\\n},\\\\n\\\\\\\"afternoon\\\\\\\": {\\\\n\\\\\\\"color\\\\\\\": \\\\\\\"warm gray\\\\\\\"\\\\n},\\\\n\\\\\\\"evening\\\\\\\": {\\\\n\\\\\\\"color\\\\\\\": \\\\\\\"orange\\\\\\\"\\\\n}\\\\n}\\\\n\\\",\\n  \\\"done\\\": true,\\n  \\\"context\\\": [1, 2, 3],\\n  \\\"total_duration\\\": 4648158584,\\n  \\\"load_duration\\\": 4071084,\\n  \\\"prompt_eval_count\\\": 36,\\n  \\\"prompt_eval_duration\\\": 439038000,\\n  \\\"eval_count\\\": 180,\\n  \\\"eval_duration\\\": 4196918000\\n}\\n```\\n\\nThe value of `response` will be a string containing JSON similar to:\\n\\n```json\\n{\\n  \\\"morning\\\": {\\n    \\\"color\\\": \\\"blue\\\"\\n  },\\n  \\\"noon\\\": {\\n    \\\"color\\\": \\\"blue-gray\\\"\\n  },\\n  \\\"afternoon\\\": {\\n    \\\"color\\\": \\\"warm gray\\\"\\n  },\\n  \\\"evening\\\": {\\n    \\\"color\\\": \\\"orange\\\"\\n  }\\n}\\n```\\n\\n#### Request (with images)\\n\\nTo submit images to multimodal models such as `llava` or `bakllava`, provide a list of base64-encoded `images`:\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llava\\\",\\n  \\\"prompt\\\":\\\"What is in this picture?\\\",\\n  \\\"stream\\\": false,\\n  \\\"images\\\": [\\\"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\\\"]\\n}'\\n```\\n\\n#### Response\\n\\n```\\n{\\n  \\\"model\\\": \\\"llava\\\",\\n  \\\"created_at\\\": \\\"2023-11-03T15:36:02.583064Z\\\",\\n  \\\"response\\\": \\\"A happy cartoon character, which is cute and cheerful.\\\",\\n  \\\"done\\\": true,\\n  \\\"context\\\": [1, 2, 3],\\n  \\\"total_duration\\\": 2938432250,\\n  \\\"load_duration\\\": 2559292,\\n  \\\"prompt_eval_count\\\": 1,\\n  \\\"prompt_eval_duration\\\": 2195557000,\\n  \\\"eval_count\\\": 44,\\n  \\\"eval_duration\\\": 736432000\\n}\\n```\\n\\n#### Request (Raw Mode)\\n\\nIn some cases, you may wish to bypass the templating system and provide a full prompt. In this case, you can use the `raw` parameter to disable templating. Also note that raw mode will not return a context.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"mistral\\\",\\n  \\\"prompt\\\": \\\"[INST] why is the sky blue? [/INST]\\\",\\n  \\\"raw\\\": true,\\n  \\\"stream\\\": false\\n}'\\n```\\n\\n#### Request (Reproducible outputs)\\n\\nFor reproducible outputs, set `temperature` to 0 and `seed` to a number:\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"mistral\\\",\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\",\\n  \\\"options\\\": {\\n    \\\"seed\\\": 123,\\n    \\\"temperature\\\": 0\\n  }\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"mistral\\\",\\n  \\\"created_at\\\": \\\"2023-11-03T15:36:02.583064Z\\\",\\n  \\\"response\\\": \\\" The sky appears blue because of a phenomenon called Rayleigh scattering.\\\",\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 8493852375,\\n  \\\"load_duration\\\": 6589624375,\\n  \\\"prompt_eval_count\\\": 14,\\n  \\\"prompt_eval_duration\\\": 119039000,\\n  \\\"eval_count\\\": 110,\\n  \\\"eval_duration\\\": 1779061000\\n}\\n```\\n\\n#### Generate request (With options)\\n\\nIf you want to set custom options for the model at runtime rather than in the Modelfile, you can do so with the `options` parameter. This example sets every available option, but you can set any of them individually and omit the ones you do not want to override.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"prompt\\\": \\\"Why is the sky blue?\\\",\\n  \\\"stream\\\": false,\\n  \\\"options\\\": {\\n    \\\"num_keep\\\": 5,\\n    \\\"seed\\\": 42,\\n    \\\"num_predict\\\": 100,\\n    \\\"top_k\\\": 20,\\n    \\\"top_p\\\": 0.9,\\n    \\\"tfs_z\\\": 0.5,\\n    \\\"typical_p\\\": 0.7,\\n    \\\"repeat_last_n\\\": 33,\\n    \\\"temperature\\\": 0.8,\\n    \\\"repeat_penalty\\\": 1.2,\\n    \\\"presence_penalty\\\": 1.5,\\n    \\\"frequency_penalty\\\": 1.0,\\n    \\\"mirostat\\\": 1,\\n    \\\"mirostat_tau\\\": 0.8,\\n    \\\"mirostat_eta\\\": 0.6,\\n    \\\"penalize_newline\\\": true,\\n    \\\"stop\\\": [\\\"\\\\n\\\", \\\"user:\\\"],\\n    \\\"numa\\\": false,\\n    \\\"num_ctx\\\": 1024,\\n    \\\"num_batch\\\": 2,\\n    \\\"num_gpu\\\": 1,\\n    \\\"main_gpu\\\": 0,\\n    \\\"low_vram\\\": false,\\n    \\\"f16_kv\\\": true,\\n    \\\"vocab_only\\\": false,\\n    \\\"use_mmap\\\": true,\\n    \\\"use_mlock\\\": false,\\n    \\\"num_thread\\\": 8\\n  }\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T19:22:45.499127Z\\\",\\n  \\\"response\\\": \\\"The sky is blue because it is the color of the sky.\\\",\\n  \\\"done\\\": true,\\n  \\\"context\\\": [1, 2, 3],\\n  \\\"total_duration\\\": 4935886791,\\n  \\\"load_duration\\\": 534986708,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 107345000,\\n  \\\"eval_count\\\": 237,\\n  \\\"eval_duration\\\": 4289432000\\n}\\n```\\n\\n#### Load a model\\n\\nIf an empty prompt is provided, the model will be loaded into memory.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/generate -d '{\\n  \\\"model\\\": \\\"llama3\\\"\\n}'\\n```\\n\\n##### Response\\n\\nA single JSON object is returned:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-12-18T19:52:07.071755Z\\\",\\n  \\\"response\\\": \\\"\\\",\\n  \\\"done\\\": true\\n}\\n```\\n\\n## Generate a chat completion\\n\\n```shell\\nPOST /api/chat\\n```\\n\\nGenerate the next message in a chat with a provided model. This is a streaming endpoint, so there will be a series of responses. Streaming can be disabled using `\\\"stream\\\": false`. The final response object will include statistics and additional data from the request.\\n\\n### Parameters\\n\\n- `model`: (required) the [model name](#model-names)\\n- `messages`: the messages of the chat, this can be used to keep a chat memory\\n\\nThe `message` object has the following fields:\\n\\n- `role`: the role of the message, either `system`, `user` or `assistant`\\n- `content`: the content of the message\\n- `images` (optional): a list of images to include in the message (for multimodal models such as `llava`)\\n\\nAdvanced parameters (optional):\\n\\n- `format`: the format to return a response in. Currently the only accepted value is `json`\\n- `options`: additional model parameters listed in the documentation for the [Modelfile](./modelfile.md#valid-parameters-and-values) such as `temperature`\\n- `stream`: if `false` the response will be returned as a single response object, rather than a stream of objects\\n- `keep_alive`: controls how long the model will stay loaded into memory following the request (default: `5m`)\\n\\n### Examples\\n\\n#### Chat Request (Streaming)\\n\\n##### Request\\n\\nSend a chat message with a streaming response.\\n\\n```shell\\ncurl http://localhost:11434/api/chat -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"why is the sky blue?\\\"\\n    }\\n  ]\\n}'\\n```\\n\\n##### Response\\n\\nA stream of JSON objects is returned:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T08:52:19.385406455-07:00\\\",\\n  \\\"message\\\": {\\n    \\\"role\\\": \\\"assistant\\\",\\n    \\\"content\\\": \\\"The\\\",\\n    \\\"images\\\": null\\n  },\\n  \\\"done\\\": false\\n}\\n```\\n\\nFinal response:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T19:22:45.499127Z\\\",\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 4883583458,\\n  \\\"load_duration\\\": 1334875,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 342546000,\\n  \\\"eval_count\\\": 282,\\n  \\\"eval_duration\\\": 4535599000\\n}\\n```\\n\\n#### Chat request (No streaming)\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/chat -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"why is the sky blue?\\\"\\n    }\\n  ],\\n  \\\"stream\\\": false\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"registry.ollama.ai/library/llama3:latest\\\",\\n  \\\"created_at\\\": \\\"2023-12-12T14:13:43.416799Z\\\",\\n  \\\"message\\\": {\\n    \\\"role\\\": \\\"assistant\\\",\\n    \\\"content\\\": \\\"Hello! How are you today?\\\"\\n  },\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 5191566416,\\n  \\\"load_duration\\\": 2154458,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 383809000,\\n  \\\"eval_count\\\": 298,\\n  \\\"eval_duration\\\": 4799921000\\n}\\n```\\n\\n#### Chat request (With History)\\n\\nSend a chat message with a conversation history. You can use this same approach to start the conversation using multi-shot or chain-of-thought prompting.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/chat -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"why is the sky blue?\\\"\\n    },\\n    {\\n      \\\"role\\\": \\\"assistant\\\",\\n      \\\"content\\\": \\\"due to rayleigh scattering.\\\"\\n    },\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"how is that different than mie scattering?\\\"\\n    }\\n  ]\\n}'\\n```\\n\\n##### Response\\n\\nA stream of JSON objects is returned:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T08:52:19.385406455-07:00\\\",\\n  \\\"message\\\": {\\n    \\\"role\\\": \\\"assistant\\\",\\n    \\\"content\\\": \\\"The\\\"\\n  },\\n  \\\"done\\\": false\\n}\\n```\\n\\nFinal response:\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"created_at\\\": \\\"2023-08-04T19:22:45.499127Z\\\",\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 8113331500,\\n  \\\"load_duration\\\": 6396458,\\n  \\\"prompt_eval_count\\\": 61,\\n  \\\"prompt_eval_duration\\\": 398801000,\\n  \\\"eval_count\\\": 468,\\n  \\\"eval_duration\\\": 7701267000\\n}\\n```\\n\\n#### Chat request (with images)\\n\\n##### Request\\n\\nSend a chat message with a conversation history.\\n\\n```shell\\ncurl http://localhost:11434/api/chat -d '{\\n  \\\"model\\\": \\\"llava\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"what is in this image?\\\",\\n      \\\"images\\\": [\\\"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\\\"]\\n    }\\n  ]\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"llava\\\",\\n  \\\"created_at\\\": \\\"2023-12-13T22:42:50.203334Z\\\",\\n  \\\"message\\\": {\\n    \\\"role\\\": \\\"assistant\\\",\\n    \\\"content\\\": \\\" The image features a cute, little pig with an angry facial expression. It's wearing a heart on its shirt and is waving in the air. This scene appears to be part of a drawing or sketching project.\\\",\\n    \\\"images\\\": null\\n  },\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 1668506709,\\n  \\\"load_duration\\\": 1986209,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 359682000,\\n  \\\"eval_count\\\": 83,\\n  \\\"eval_duration\\\": 1303285000\\n}\\n```\\n\\n#### Chat request (Reproducible outputs)\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/chat -d '{\\n  \\\"model\\\": \\\"llama3\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"Hello!\\\"\\n    }\\n  ],\\n  \\\"options\\\": {\\n    \\\"seed\\\": 101,\\n    \\\"temperature\\\": 0\\n  }\\n}'\\n```\\n\\n##### Response\\n\\n```json\\n{\\n  \\\"model\\\": \\\"registry.ollama.ai/library/llama3:latest\\\",\\n  \\\"created_at\\\": \\\"2023-12-12T14:13:43.416799Z\\\",\\n  \\\"message\\\": {\\n    \\\"role\\\": \\\"assistant\\\",\\n    \\\"content\\\": \\\"Hello! How are you today?\\\"\\n  },\\n  \\\"done\\\": true,\\n  \\\"total_duration\\\": 5191566416,\\n  \\\"load_duration\\\": 2154458,\\n  \\\"prompt_eval_count\\\": 26,\\n  \\\"prompt_eval_duration\\\": 383809000,\\n  \\\"eval_count\\\": 298,\\n  \\\"eval_duration\\\": 4799921000\\n}\\n```\\n\\n## Create a Model\\n\\n```shell\\nPOST /api/create\\n```\\n\\nCreate a model from a [`Modelfile`](./modelfile.md). It is recommended to set `modelfile` to the content of the Modelfile rather than just set `path`. This is a requirement for remote create. Remote model creation must also create any file blobs, fields such as `FROM` and `ADAPTER`, explicitly with the server using [Create a Blob](#create-a-blob) and the value to the path indicated in the response.\\n\\n### Parameters\\n\\n- `name`: name of the model to create\\n- `modelfile` (optional): contents of the Modelfile\\n- `stream`: (optional) if `false` the response will be returned as a single response object, rather than a stream of objects\\n- `path` (optional): path to the Modelfile\\n\\n### Examples\\n\\n#### Create a new model\\n\\nCreate a new model from a `Modelfile`.\\n\\n##### Request\\n\\n```shell\\ncurl http://localhost:11434/api/create -d '{\\n  \\\"name\\\": \\\"mario\\\",\\n  \\\"modelfile\\\": \\\"FROM llama3\\\\nSYSTEM You are mario from Super Mario Bros.\\\"\\n}'\\n```\\n\\n##### Response\\n\\nA stream of JSON objects. Notice that the final JSON object shows a `\\\"status\\\": \\\"success\\\"`.\\n\\n```json\\n{\\\"status\\\":\\\"reading model metadata\\\"}\\n{\\\"status\\\":\\\"creating system layer\\\"}\\n{\\\"status\\\":\\\"using already created layer sha256:22f7f8ef5f4c791c1b03d7eb414399294764d7cc82c7e94aa81a1feb80a983a2\\\"}\\n{\\\"status\\\":\\\"using already created layer sha256:8c17c2ebb0ea011be9981cc3922db8ca8fa61e828c5d3f44cb6ae342bf80460b\\\"}\\n{\\\"status\\\":\\\"using already created layer sha256:7c23fb36d80141c4ab8cdbb61ee4790102ebd2bf7aeff414453177d4f2110e5d\\\"}\\n{\\\"status\\\":\\\"using already created layer sha256:2e0493f67d0c8c9c68a8aeacdf6a38a2151cb3c4c1d42accf296e19810527988\\\"}\\n{\\\"status\\\":\\\"using already created layer sha256:2759286baa875dc22de5394b4a925701b1896a7e3f8e53275c36f75a877a82c9\\\"}\\n{\\\"status\\\":\\\"writing layer sha256:df30045fe90f0d750db82a058109cecd6d4de9c90a3d75b19c09e5f64580bb42\\\"}\\n{\\\"status\\\":\\\"writing layer sha256:f18a68eb09bf925bb1b669490407c1b1251c5db98dc4d3d81f3088498ea55690\\\"}\\n{\\\"status\\\":\\\"writing manifest\\\"}\\n{\\\"status\\\":\\\"success\\\"}\\n```\\n\\n### Check if a Blob Exists\\n\\n```shell\\nHEAD /api/blobs/:digest\\n```\\n\\nEnsures that the file blob used for a FROM or ADAPTER field exists on the server. This is checking your Ollama server and not Ollama.ai.\\n\\n#### Query Parameters\\n\\n- `digest`: the SHA256 digest of the blob\\n\\n#### Examples\\n\\n##### Request\\n\\n```shell\\ncurl -I http://localhost:11434/api/blobs/sha256:29fdb92e57cf0827ded04ae6461b5931d01fa595843f55d36f5b275a52087dd2\\n```\\n\\n##### Response\\n\\nReturn 200 OK if the blob exists, 404 Not Found if it does not.\\n\\n### Create a Blob\\n\\n```shell\\nPOST /api/blobs/:digest\\n```\\n\\nCreate a blob from a file on the server. Returns the server file path.\\n\\n#### Query Parameters\\n\\n- `digest`: the expected SHA256 digest of the file\\n\\n#### Examples\\n\\n##### Request\\n\\n```shell\\ncurl -T model.bin -X POST http://localhost:11434/api/blobs/sha256:29fdb92e57cf0827ded04ae6461b5931d01fa595843f55d36f5b275a52087dd2\\n```\\n\\n##### Response\\n\\nReturn 201 Created if the blob was successfully created, 400 Bad Request if the digest used is not expected.\\n\\n## List Local Models\\n\\n```shell\\nGET /api/tags\\n```\\n\\nList models that are available locally.\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/tags\\n```\\n\\n#### Response\\n\\nA single JSON object will be returned.\\n\\n```json\\n{\\n  \\\"models\\\": [\\n    {\\n      \\\"name\\\": \\\"codellama:13b\\\",\\n      \\\"modified_at\\\": \\\"2023-11-04T14:56:49.277302595-07:00\\\",\\n      \\\"size\\\": 7365960935,\\n      \\\"digest\\\": \\\"9f438cb9cd581fc025612d27f7c1a6669ff83a8bb0ed86c94fcf4c5440555697\\\",\\n      \\\"details\\\": {\\n        \\\"format\\\": \\\"gguf\\\",\\n        \\\"family\\\": \\\"llama\\\",\\n        \\\"families\\\": null,\\n        \\\"parameter_size\\\": \\\"13B\\\",\\n        \\\"quantization_level\\\": \\\"Q4_0\\\"\\n      }\\n    },\\n    {\\n      \\\"name\\\": \\\"llama3:latest\\\",\\n      \\\"modified_at\\\": \\\"2023-12-07T09:32:18.757212583-08:00\\\",\\n      \\\"size\\\": 3825819519,\\n      \\\"digest\\\": \\\"fe938a131f40e6f6d40083c9f0f430a515233eb2edaa6d72eb85c50d64f2300e\\\",\\n      \\\"details\\\": {\\n        \\\"format\\\": \\\"gguf\\\",\\n        \\\"family\\\": \\\"llama\\\",\\n        \\\"families\\\": null,\\n        \\\"parameter_size\\\": \\\"7B\\\",\\n        \\\"quantization_level\\\": \\\"Q4_0\\\"\\n      }\\n    }\\n  ]\\n}\\n```\\n\\n## Show Model Information\\n\\n```shell\\nPOST /api/show\\n```\\n\\nShow information about a model including details, modelfile, template, parameters, license, and system prompt.\\n\\n### Parameters\\n\\n- `name`: name of the model to show\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/show -d '{\\n  \\\"name\\\": \\\"llama3\\\"\\n}'\\n```\\n\\n#### Response\\n\\n```json\\n{\\n  \\\"modelfile\\\": \\\"# Modelfile generated by \\\\\\\"ollama show\\\\\\\"\\\\n# To build a new Modelfile based on this one, replace the FROM line with:\\\\n# FROM llava:latest\\\\n\\\\nFROM /Users/matt/.ollama/models/blobs/sha256:200765e1283640ffbd013184bf496e261032fa75b99498a9613be4e94d63ad52\\\\nTEMPLATE \\\\\\\"\\\\\\\"\\\\\\\"{{ .System }}\\\\nUSER: {{ .Prompt }}\\\\nASSISTANT: \\\\\\\"\\\\\\\"\\\\\\\"\\\\nPARAMETER num_ctx 4096\\\\nPARAMETER stop \\\\\\\"\\\\u003c/s\\\\u003e\\\\\\\"\\\\nPARAMETER stop \\\\\\\"USER:\\\\\\\"\\\\nPARAMETER stop \\\\\\\"ASSISTANT:\\\\\\\"\\\",\\n  \\\"parameters\\\": \\\"num_ctx                        4096\\\\nstop                           \\\\u003c/s\\\\u003e\\\\nstop                           USER:\\\\nstop                           ASSISTANT:\\\",\\n  \\\"template\\\": \\\"{{ .System }}\\\\nUSER: {{ .Prompt }}\\\\nASSISTANT: \\\",\\n  \\\"details\\\": {\\n    \\\"format\\\": \\\"gguf\\\",\\n    \\\"family\\\": \\\"llama\\\",\\n    \\\"families\\\": [\\\"llama\\\", \\\"clip\\\"],\\n    \\\"parameter_size\\\": \\\"7B\\\",\\n    \\\"quantization_level\\\": \\\"Q4_0\\\"\\n  }\\n}\\n```\\n\\n## Copy a Model\\n\\n```shell\\nPOST /api/copy\\n```\\n\\nCopy a model. Creates a model with another name from an existing model.\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/copy -d '{\\n  \\\"source\\\": \\\"llama3\\\",\\n  \\\"destination\\\": \\\"llama3-backup\\\"\\n}'\\n```\\n\\n#### Response\\n\\nReturns a 200 OK if successful, or a 404 Not Found if the source model doesn't exist.\\n\\n## Delete a Model\\n\\n```shell\\nDELETE /api/delete\\n```\\n\\nDelete a model and its data.\\n\\n### Parameters\\n\\n- `name`: model name to delete\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl -X DELETE http://localhost:11434/api/delete -d '{\\n  \\\"name\\\": \\\"llama3:13b\\\"\\n}'\\n```\\n\\n#### Response\\n\\nReturns a 200 OK if successful, 404 Not Found if the model to be deleted doesn't exist.\\n\\n## Pull a Model\\n\\n```shell\\nPOST /api/pull\\n```\\n\\nDownload a model from the ollama library. Cancelled pulls are resumed from where they left off, and multiple calls will share the same download progress.\\n\\n### Parameters\\n\\n- `name`: name of the model to pull\\n- `insecure`: (optional) allow insecure connections to the library. Only use this if you are pulling from your own library during development.\\n- `stream`: (optional) if `false` the response will be returned as a single response object, rather than a stream of objects\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/pull -d '{\\n  \\\"name\\\": \\\"llama3\\\"\\n}'\\n```\\n\\n#### Response\\n\\nIf `stream` is not specified, or set to `true`, a stream of JSON objects is returned:\\n\\nThe first object is the manifest:\\n\\n```json\\n{\\n  \\\"status\\\": \\\"pulling manifest\\\"\\n}\\n```\\n\\nThen there is a series of downloading responses. Until any of the download is completed, the `completed` key may not be included. The number of files to be downloaded depends on the number of layers specified in the manifest.\\n\\n```json\\n{\\n  \\\"status\\\": \\\"downloading digestname\\\",\\n  \\\"digest\\\": \\\"digestname\\\",\\n  \\\"total\\\": 2142590208,\\n  \\\"completed\\\": 241970\\n}\\n```\\n\\nAfter all the files are downloaded, the final responses are:\\n\\n```json\\n{\\n    \\\"status\\\": \\\"verifying sha256 digest\\\"\\n}\\n{\\n    \\\"status\\\": \\\"writing manifest\\\"\\n}\\n{\\n    \\\"status\\\": \\\"removing any unused layers\\\"\\n}\\n{\\n    \\\"status\\\": \\\"success\\\"\\n}\\n```\\n\\nif `stream` is set to false, then the response is a single JSON object:\\n\\n```json\\n{\\n  \\\"status\\\": \\\"success\\\"\\n}\\n```\\n\\n## Push a Model\\n\\n```shell\\nPOST /api/push\\n```\\n\\nUpload a model to a model library. Requires registering for ollama.ai and adding a public key first.\\n\\n### Parameters\\n\\n- `name`: name of the model to push in the form of `<namespace>/<model>:<tag>`\\n- `insecure`: (optional) allow insecure connections to the library. Only use this if you are pushing to your library during development.\\n- `stream`: (optional) if `false` the response will be returned as a single response object, rather than a stream of objects\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/push -d '{\\n  \\\"name\\\": \\\"mattw/pygmalion:latest\\\"\\n}'\\n```\\n\\n#### Response\\n\\nIf `stream` is not specified, or set to `true`, a stream of JSON objects is returned:\\n\\n```json\\n{ \\\"status\\\": \\\"retrieving manifest\\\" }\\n```\\n\\nand then:\\n\\n```json\\n{\\n  \\\"status\\\": \\\"starting upload\\\",\\n  \\\"digest\\\": \\\"sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711ab\\\",\\n  \\\"total\\\": 1928429856\\n}\\n```\\n\\nThen there is a series of uploading responses:\\n\\n```json\\n{\\n  \\\"status\\\": \\\"starting upload\\\",\\n  \\\"digest\\\": \\\"sha256:bc07c81de745696fdf5afca05e065818a8149fb0c77266fb584d9b2cba3711ab\\\",\\n  \\\"total\\\": 1928429856\\n}\\n```\\n\\nFinally, when the upload is complete:\\n\\n```json\\n{\\\"status\\\":\\\"pushing manifest\\\"}\\n{\\\"status\\\":\\\"success\\\"}\\n```\\n\\nIf `stream` is set to `false`, then the response is a single JSON object:\\n\\n```json\\n{ \\\"status\\\": \\\"success\\\" }\\n```\\n\\n## Generate Embeddings\\n\\n```shell\\nPOST /api/embeddings\\n```\\n\\nGenerate embeddings from a model\\n\\n### Parameters\\n\\n- `model`: name of model to generate embeddings from\\n- `prompt`: text to generate embeddings for\\n\\nAdvanced parameters:\\n\\n- `options`: additional model parameters listed in the documentation for the [Modelfile](./modelfile.md#valid-parameters-and-values) such as `temperature`\\n- `keep_alive`: controls how long the model will stay loaded into memory following the request (default: `5m`)\\n\\n### Examples\\n\\n#### Request\\n\\n```shell\\ncurl http://localhost:11434/api/embeddings -d '{\\n  \\\"model\\\": \\\"all-minilm\\\",\\n  \\\"prompt\\\": \\\"Here is an article about llamas...\\\"\\n}'\\n```\\n\\n#### Response\\n\\n```json\\n{\\n  \\\"embedding\\\": [\\n    0.5670403838157654, 0.009260174818336964, 0.23178744316101074, -0.2916173040866852, -0.8924556970596313,\\n    0.8785552978515625, -0.34576427936553955, 0.5742510557174683, -0.04222835972905159, -0.137906014919281\\n  ]\\n}\\n```\",\"embedding\":\"{0.5900706648826599, 0.6360538601875305, -0.059724047780036926, -0.24934932589530945, -0.3855472207069397, -0.3825725018978119, 0.25829097628593445, 0.3250914514064789, 0.4043090343475342, 1.005517601966858, 0.26668697595596313, 0.29431554675102234, 0.33063095808029175, -0.17841596901416779, -0.23538999259471893, 0.1007184386253357, 0.24214425683021545, -0.3453691601753235, -0.10882236063480377, -0.3119538724422455, -0.6167795658111572, 0.7573468089103699, -0.9326998591423035, 0.1318858414888382, -0.4779558777809143, 0.09325101971626282, 0.26987186074256897, 0.39434483647346497, 0.8220316171646118, 0.12413831800222397, 0.09547188878059387, 0.5425748825073242, 0.16355842351913452, -0.6711742877960205, 0.05060605704784393, -0.015404647216200829, 0.1925535798072815, -0.5005543231964111, -0.055044226348400116, -1.1939641237258911, 0.6288540959358215, -0.43617764115333557, 0.33957964181900024, -0.67169588804245, -0.46773919463157654, -0.5191217660903931, -0.16295099258422852, 0.07550030946731567, -0.05470968410372734, -0.6717217564582825, -0.1193811446428299, 0.5135992765426636, 0.37188029289245605, -0.6275998950004578, -0.38554778695106506, -0.7923212647438049, -0.18467079102993011, -0.07364435493946075, -0.5284991264343262, 0.3316316604614258, 0.11984451115131378, 0.341085284948349, 0.1815391480922699, -0.6275038123130798, -0.11246669292449951, 0.7046987414360046, -0.5201464295387268, 0.27138617634773254, 0.004577074199914932, 0.1997784823179245, -0.6841527223587036, 0.991428554058075, -0.1650926172733307, -0.6952431797981262, -0.6580343842506409, 0.3707219958305359, 0.2500160336494446, 0.132219597697258, 0.03898809850215912, 0.31506621837615967, 0.03387279808521271, 1.0366237163543701, 0.19832473993301392, 0.4840329587459564, -0.19865268468856812, -0.672484278678894, 0.2886975407600403, 0.1329093873500824, 0.0917523056268692, -0.033265117555856705, -0.3404887020587921, 0.5894606709480286, -0.4986826777458191, 0.07348322868347168, 0.32765352725982666, 0.3973281681537628, -0.08547084033489227, 0.37761539220809937, -0.770906925201416, -0.21172776818275452, 0.5878730416297913, 1.3130249977111816, -0.4069674611091614, -0.14650435745716095, -0.5378377437591553, 1.1084585189819336, 0.5335499048233032, 0.216160386800766, -0.9958411455154419, -0.5940506458282471, 0.30202779173851013, 0.058057576417922974, -0.2748062312602997, -0.48650139570236206, -0.7019079327583313, 0.2807123064994812, 0.4057760238647461, 0.23635295033454895, -1.0184440612792969, -0.8493787050247192, -0.50477534532547, -0.2666919231414795, -0.22937598824501038, -0.7909696102142334, -0.23724207282066345, -0.5566719770431519, -0.08675997704267502, 0.7802563905715942, 0.09251243621110916, 0.5251890420913696, 0.11187823861837387, -0.26416927576065063, 0.7712963819503784, 0.6878520846366882, -0.4957883358001709, 0.018647877499461174, -0.05665779858827591, 0.4243943691253662, 0.9126219153404236, -0.25966155529022217, 0.26247555017471313, -0.2397366762161255, 0.1309889703989029, 1.4675991535186768, -0.5980240106582642, 0.2951101064682007, -0.01902816630899906, -0.6080822944641113, -0.7594301104545593, 0.24577441811561584, -0.2869948744773865, -0.28026172518730164, 0.0001090681180357933, 0.3039364814758301, -0.4256592392921448, 0.25300806760787964, -0.5907009840011597, 0.015324398875236511, 0.07065846771001816, -0.07644025981426239, 0.2865165174007416, 0.3838771879673004, -0.6865692734718323, 0.8482075929641724, 0.2087961882352829, -0.034163862466812134, -0.4967653751373291, -0.3578980565071106, -0.039666566997766495, -0.864822268486023, 0.13709251582622528, -0.11023852974176407, -0.12928688526153564, 0.1714249849319458, 0.4086619019508362, 0.33354026079177856, -0.09546808898448944, 0.10874596983194351, 0.22311906516551971, -0.24760352075099945, 0.0677420124411583, 0.6199430227279663, 0.5018585920333862, 0.36916959285736084, 0.09684144705533981, 0.08759055286645889, 0.11461657285690308, 0.14526930451393127, 0.1242256611585617, 0.3974422812461853, 0.15024706721305847, 0.43589848279953003, -0.08826673030853271, 0.35825115442276, -0.35668936371803284, 0.1353701651096344, -0.9081649780273438, 0.493874728679657, -0.4251381754875183, -0.47994357347488403, -0.47818058729171753, 0.07110963016748428, -0.40034249424934387, 0.02421373873949051, -0.5756977200508118, 0.14361229538917542, 0.09474124014377594, 0.6027592420578003, -0.23123672604560852, -0.1261894404888153, 0.5596924424171448, -0.06550464779138565, -0.6493356823921204, 0.10456398129463196, 0.5956968665122986, -0.12740138173103333, -0.7262893319129944, 0.03404639661312103, 0.5307667851448059, 0.1625639796257019, -0.3371020555496216, 0.3062177002429962, -0.05799353867769241, 0.26129239797592163, -0.3754948377609253, -0.44343090057373047, 0.03260178118944168, 0.10846208781003952, -0.04749005287885666, 0.12131064385175705, -0.01486014574766159, 0.32880347967147827, -0.23751267790794373, 0.15270192921161652, 0.2930259704589844, 0.21684382855892181, 0.5837814807891846, -0.05042414367198944, 0.5163495540618896, 0.23897401988506317, -0.2922787666320801, 0.26029354333877563, 0.2939147353172302, 0.16827557981014252, 0.8417642116546631, -0.2533419132232666, -0.13745760917663574, -0.47049176692962646, -0.3614639341831207, 0.8624823093414307, -0.9180412292480469, 1.2036157846450806, 0.9736793041229248, 0.2061954289674759, -0.5470932722091675, -0.40280473232269287, 0.3831157386302948, 0.9042395949363708, -0.5612630248069763, 0.03878426551818848, 0.011158011853694916, -0.14086894690990448, 0.15584857761859894, -0.35387930274009705, 0.08805888891220093, 0.2138495296239853, -0.029681215062737465, -0.20404812693595886, -0.3231978416442871, -0.8567746877670288, -0.24486559629440308, -0.20566292107105255, -0.9501284956932068, -0.08500895649194717, -0.2571351230144501, -0.1955944299697876, 0.28912097215652466, -0.4352327883243561, 0.3340899348258972, -0.8361693620681763, -0.03626508265733719, 0.10672752559185028, -0.23918694257736206, -0.08652935922145844, 0.4362899661064148, -0.10322391241788864, -1.08158278465271, -0.10146310925483704, -0.9244974255561829, 0.2563951313495636, -0.45882606506347656, -0.07245595753192902, 0.32917430996894836, -0.6633805632591248, -0.15752799808979034, -0.3008800745010376, 0.6959351897239685, 0.1005401536822319, 0.3571290075778961, -0.20127132534980774, -0.18723750114440918, -0.5326687693595886, -0.1317804455757141, 0.033890873193740845, -0.43030551075935364, 0.3400210738182068, 0.16051237285137177, -0.046556130051612854, 0.02347688004374504, 0.1482992321252823, 0.19954119622707367, 0.3328215181827545, -0.2565041184425354, 0.439410537481308, 0.05001115798950195, 0.40641114115715027, 0.8145769834518433, 0.42344731092453003, -0.013027340173721313, -0.9756314754486084, -0.354022353887558, -0.2441481053829193, 0.16595789790153503, 0.20316264033317566, 0.07279738783836365, 0.6852127909660339, -0.17752471566200256, -0.8769331574440002, -0.18881294131278992, -0.24573010206222534, -0.024696478620171547, -0.5442427396774292, -0.347725510597229, 0.24663986265659332, 0.5353771448135376, 1.2199811935424805, -0.5303259491920471, -0.5633079409599304, -0.9013671875, 0.5074808597564697, 0.4552323520183563, -0.17343562841415405, 0.30061259865760803, 0.3860608637332916, -0.6567258238792419, 1.0713101625442505, 1.0940018892288208, -0.8494130969047546, -0.009389201179146767, 0.3043873608112335, -0.13959799706935883, -0.403687983751297, 0.43102946877479553, -0.1132369339466095, -0.0983145534992218, 0.6101511120796204, -0.404288649559021, 0.4699018895626068, 0.10188685357570648, 0.009092704392969608, 0.1532151699066162, 0.48471736907958984, 0.21410125494003296, -0.13654087483882904, -0.012124922126531601, -0.6391072273254395, 0.1079137995839119, -0.08161032199859619, 0.5791541934013367, -1.0426108837127686, -0.17890313267707825, -0.18399062752723694, -0.46293583512306213, -0.20873495936393738, 0.21069227159023285, -0.3185902535915375, 0.5791106820106506, 0.2481277883052826, 0.1518019288778305, -0.4348851442337036, -0.30699461698532104, 0.6556584239006042, -0.2638532519340515, 0.5184112787246704, 0.7230213284492493, -0.12243768572807312, 0.13412633538246155, -0.43061184883117676, -0.04226896911859512, -0.6497160196304321, 0.11592453718185425, -0.1830114722251892, 0.06004074215888977, -0.022540487349033356, -0.6505580544471741, -0.5064353942871094, -0.045951925218105316, 0.42629802227020264, 0.5788418650627136, 0.16343477368354797, 0.031219899654388428, -0.6015679836273193, 0.1507425755262375, -0.2544926702976227, -0.062085457146167755, -0.09610365331172943, -0.4148155748844147, 0.6875230669975281, 0.059101708233356476, 0.06431756913661957, 0.45280447602272034, 0.0902399867773056, -0.1221497505903244, -0.09373284876346588, 0.5221707224845886, 0.6888588666915894, -0.8279868960380554, 0.25174036622047424, -0.021997619420289993, -0.09724488854408264, 0.810401976108551, -0.6174579858779907, -0.3624759912490845, 0.5512130260467529, 1.016433835029602, -0.5672653317451477, 0.11938856542110443, -0.0448991097509861, -0.13381317257881165, -0.14099517464637756, -0.17025457322597504, -0.27343079447746277, -0.4934961795806885, -0.18911483883857727, -0.5413792133331299, 1.215126633644104, 0.6669891476631165, -0.6872225999832153, 0.07912179082632065, -0.3984510898590088, 0.23717434704303741, 0.32657620310783386, 0.1745060533285141, 0.10531552881002426, 0.4604488015174866, -0.28392061591148376, 0.31411898136138916, -0.21166813373565674, -0.31883230805397034, -0.5454503893852234, 0.20382750034332275, -0.29041045904159546, 0.0956573411822319, -0.6066230535507202, -0.4160151481628418, 0.4686223864555359, 0.03919171169400215, 0.061083775013685226, 0.3691941499710083, 0.13083487749099731, -0.2509683072566986, 0.1876283884048462, -0.1667346954345703, -0.5295746326446533, -0.22117505967617035, 0.7903029322624207, 0.4834500551223755, 0.38858532905578613, 0.8121269345283508, -0.10389470309019089, 0.41665324568748474, 0.7974596619606018, 0.04447922110557556, -0.8300595879554749, -0.07485479861497879, 0.09654416143894196, 0.48358213901519775, 0.18064171075820923, 0.19105972349643707, 0.04649820551276207, -0.8824346661567688, 0.7979193329811096, -0.153528094291687, -0.3820456266403198, 0.8427461385726929, -0.6335217952728271, -0.19694733619689941, 0.14987166225910187, -0.4497357904911041, 0.41777244210243225, 0.052795082330703735, -0.1143614649772644, 0.40009909868240356, 0.05121399462223053, -0.5770326852798462, -0.5530792474746704, -0.47484949231147766, -0.23575571179389954, 0.7430471181869507, 0.032993827015161514, 0.6908812522888184, -0.41003742814064026, -0.9843588471412659, 0.5953019261360168, -0.9357540011405945, -0.005680665373802185, -0.23150837421417236, 0.10943092405796051, 0.13411223888397217, 0.14225372672080994, 0.16246727108955383, 0.15390193462371826, -0.6710536479949951, -0.5652588605880737, -0.2564338445663452, -0.1264481544494629, 0.4972306787967682, -0.5227003693580627, 0.023665115237236023, 0.8978342413902283, -0.023350790143013, -0.6986470818519592, -0.2664259374141693, 0.4129452109336853, 0.036721572279930115, 0.8096534013748169, 0.3948647379875183, -0.5433996915817261, -0.5331268906593323, -0.5021281242370605, 0.2657386064529419, -0.189749613404274, -0.19541451334953308, -0.715587317943573, -0.03179905563592911, -0.47615018486976624, 0.1939346343278885, 0.48565030097961426, -0.932881772518158, 0.01887534372508526, 0.29872947931289673, 0.5125587582588196, -0.2054484784603119, -0.13300678133964539, -0.3096556067466736, 0.5949546694755554, 0.10717619955539703, 0.7884690761566162, -0.8878154754638672, -0.2159687578678131, -0.08707870543003082, 0.29110172390937805, 0.2864358127117157, 0.703946590423584, 0.09570765495300293, -0.007842980325222015, 0.13374242186546326, 0.12589812278747559, 0.09391586482524872, 1.1621688604354858, -0.201022669672966, -0.16533263027668, -0.14650148153305054, -0.10335959494113922, -0.4737674593925476, -0.24364519119262695, 0.23098184168338776, -0.023022230714559555, 0.06075397506356239, -0.5744832754135132, 0.7097117304801941, 0.027802087366580963, 0.18845614790916443, 0.3388826847076416, 0.4670524001121521, -0.6371490955352783, 0.057964764535427094, -0.46632182598114014, -0.7208464741706848, 0.9928094744682312, -0.5395020246505737, -0.5811604261398315, -0.2529066205024719, -0.4787514805793762, 0.3435874283313751, -0.5884416699409485, 0.38208848237991333, 1.273906946182251, -0.03712533414363861, -0.22470174729824066, -1.0957202911376953, 0.21285328269004822, 0.1490025520324707, -0.43850424885749817, -0.050574835389852524, 0.6035364866256714, -0.4782923758029938, -0.8996595144271851, -0.5364136099815369, -0.7064454555511475, -0.6816042065620422, 0.9130887985229492, 0.8899227976799011, 0.2741219401359558, 0.4534929096698761, 0.24210992455482483, -1.0414115190505981, -0.8191874027252197, 0.6737123131752014, 0.973655641078949, -0.10872751474380493, 0.742239773273468, 0.6856663823127747, 0.4643341898918152, 0.7925019860267639, -0.4442647695541382, -0.22665515542030334, -0.43878182768821716, 0.49116018414497375, -0.4252566695213318, -0.31246230006217957, 0.14685648679733276, 0.6418996453285217, -0.539324939250946, -0.8263832330703735, -1.1274176836013794, -0.5675585269927979, -0.0526726096868515, 0.026464514434337616, -0.3330714702606201, -0.4098779559135437, -1.0292472839355469, 0.6664345264434814, 0.045827969908714294, 0.5404548048973083, -0.2900817394256592, 0.2591378688812256, -0.2679348587989807, -0.9583183526992798, -0.13155843317508698, 1.1097897291183472, -0.0030216537415981293, 0.1412665694952011, -0.7435975074768066, -0.4089180827140808, -0.4223686754703522, 0.24968378245830536, 0.2627091407775879, -0.12853986024856567, 0.16843827068805695, 0.580742597579956, -0.5241921544075012, 0.8438361883163452, -0.16111862659454346, 0.6865265965461731, 0.5256690979003906, -0.35300230979919434, -0.9412438273429871, -0.1236993819475174, 0.48603925108909607, -0.13072501122951508, 0.009754076600074768, 0.3665768504142761, -0.2561548054218292, -0.14312899112701416, 0.5753104090690613, 0.416694700717926, -0.5000360608100891, 0.37920457124710083, -0.5538390278816223, 0.18664027750492096, -0.965678870677948, -0.05357964336872101, 0.007069088518619537, 0.41157129406929016, -0.46666237711906433, -0.06854173541069031, -0.05818022042512894, 0.5195974707603455, -0.09314410388469696, 0.10480314493179321, -0.6695516109466553, -0.018484994769096375, -1.0353894233703613, 0.4650839567184448, -0.02663274109363556, -0.337192565202713, 0.02575431764125824, 0.18756961822509766, 0.05718586593866348, -0.3523566722869873, -0.9795584678649902, 0.5804407000541687, 0.02474098652601242, -0.20619016885757446, 0.3151262402534485, -0.22553414106369019, -0.25247541069984436, -0.4363844394683838, -0.6595486402511597, -0.02453501895070076, 0.4075453579425812, -0.5662453770637512, -0.34719276428222656, 0.2575819492340088, -0.12492364645004272, 0.22044390439987183, 0.3523585796356201, 0.9780771732330322, 0.6672165989875793, -0.35199329257011414, 0.14863336086273193, 0.7489506602287292, -0.5319409966468811, -0.5574723482131958, -0.6006779670715332, 0.3104425072669983, 0.3270503282546997, 0.6824307441711426, -0.35364603996276855, 0.6745905876159668, 0.9663869142532349, -0.2444373369216919, -0.04204858839511871, 0.35485386848449707, 0.8203111290931702, -0.4031088054180145, -0.1675397753715515, -0.5368801951408386, -0.04646119475364685, -0.7898346185684204, 0.7327420711517334, 0.4466998279094696, -0.10515427589416504, 0.05768735706806183, -0.3767014145851135, 0.5836786031723022, 0.23257234692573547, -0.18438220024108887, -0.8109809160232544, 0.8062153458595276, 0.033335424959659576, -0.5038557648658752, -0.2596454620361328, 0.025505661964416504, -0.19037340581417084, -0.13143916428089142, -1.1011574268341064, -0.1996297836303711, 0.3469407856464386, -0.8524391651153564, 0.15728285908699036, -0.32605546712875366, 0.24181868135929108, -0.21945224702358246, 0.4702163338661194, -0.48655611276626587, 0.2311258614063263, 0.0338779091835022, -0.3399132192134857, 0.41416847705841064, -1.2125457525253296, -0.5217543840408325, 0.03995957225561142, -0.38175466656684875, -0.4689295291900635, -0.8369284868240356, 0.7877164483070374, 0.5628061294555664, -0.03687315434217453, 0.026539910584688187, -0.5568859577178955, 0.06873287260532379, -0.16451150178909302, 0.2904662787914276, -1.1396926641464233, 0.13743850588798523, -0.4177117943763733, 0.33863046765327454, 0.10175277292728424, 0.39249444007873535, -0.13809481263160706, 0.11543881893157959, 0.6495093107223511, 0.1573893129825592, 0.35066795349121094, 0.013072831556200981, -0.03171724081039429, -0.457636296749115, 0.33981871604919434, 0.4067040681838989, -0.18298305571079254, 0.05882822349667549, 0.3443028926849365, -0.30664652585983276, 0.6849362254142761, 0.5393533110618591, 0.02461610548198223, -0.07991228997707367, 0.35212433338165283, -0.44572657346725464, -0.9307392239570618, -0.18179406225681305, 0.9035734534263611, 0.40927690267562866, -0.10541155934333801, 0.5123471021652222, -0.4589240550994873, -0.3235875070095062, 0.1072830781340599, -0.2509225010871887, -0.7684129476547241, 0.22681033611297607, -0.21837152540683746, -0.2841501533985138, -0.36145150661468506, 0.44015321135520935, -0.3760127127170563, -1.4609004259109497, -0.2828715145587921, 0.14652132987976074, 1.1768999099731445, -0.1171431839466095, 0.06640107929706573, 0.19135428965091705, 0.9495717287063599, 0.5307730436325073, 0.3294450342655182, 0.08760479092597961, -0.3563297390937805, 0.4961504340171814, 0.17652156949043274, 0.44817978143692017, -0.2080613374710083, -0.7192589640617371, 0.5104105472564697, -0.5669906735420227, 0.0025235339999198914, 0.11010552942752838, 0.2650828957557678, -0.36537694931030273, -0.14737635850906372, -0.37843984365463257, -0.4703184962272644, -0.6807056069374084, -0.12406180799007416, -0.3796232342720032, -0.0215672105550766, 0.7870893478393555, -0.2810278832912445, -0.03189912438392639, 0.4168449938297272, 0.634863018989563, 0.5418192148208618, -0.18042288720607758, 1.0416721105575562, 0.18136760592460632, 0.5908799171447754, 0.5963493585586548, -0.04617784172296524, 0.14582110941410065, -0.4655320346355438, -0.14453785121440887, 0.4831826686859131, 0.4429951608181, -0.2988679111003876, 0.212180033326149, -0.9373913407325745, -0.7576687335968018, -0.1868412345647812, 0.06664406508207321, -0.28096696734428406, -0.8455129265785217, 0.9222334623336792, -0.18086351454257965, -0.3692063093185425, 0.11099264025688171, 0.8070393800735474, 0.1983765959739685, 0.11981111764907837, 0.03025800734758377, 0.4608314037322998, 0.1700427383184433, 0.02202572673559189, -0.2043774276971817, 0.15276208519935608, -0.2737136781215668, -0.7812902927398682, 0.11660102009773254, -0.2541331350803375, -0.4411500096321106, -0.07939372956752777, 0.27563217282295227, 0.08721873909235, 0.49990585446357727, 0.7826148271560669, 0.4714694619178772, 0.3431999683380127, -0.7036107778549194, -0.6401554346084595, 0.6953560709953308, 0.7859030961990356, -0.16942578554153442, 0.779793381690979, 0.8749161958694458, -0.7148950099945068, -0.4017825722694397, 0.025937847793102264, 0.736850380897522, -0.16597849130630493, -0.3195900321006775, 0.1978105753660202, 0.6910035014152527, -0.6445482969284058, -0.6249163746833801, -0.22473379969596863, 0.4553963840007782, -0.06477765738964081, -0.20967864990234375, -0.31419163942337036, -0.2508295178413391, -0.7437293529510498, 0.14098362624645233, -0.33667442202568054, 0.7094827890396118, -0.14489006996154785, -0.5314722061157227, 0.22506137192249298, -0.8021489381790161, 4.4983906745910645, 0.3437231779098511, 0.540692925453186, 0.081858329474926, 0.36667829751968384, 0.2600131332874298, 1.032260775566101, 0.13494805991649628, 0.31730785965919495, -0.09218752384185791, 0.194141685962677, -0.011379875242710114, 0.18771860003471375, 0.22945156693458557, -0.08045211434364319, 0.2585020065307617, -0.8184081315994263, 0.20925205945968628, 0.030651789158582687, -0.594619631767273, -0.3910916745662689, 0.04829812049865723, 0.5507872104644775, 0.9039176106452942, 0.45492249727249146, 0.46230974793434143, -0.2599509358406067, -0.22916117310523987, 0.4702603220939636, -0.5215504765510559, 0.11103198677301407, -0.253766268491745, 0.5577888488769531, -0.08225791156291962, -0.07275788486003876, 0.0936526507139206, 0.015138102695345879, -0.4190593361854553, -0.03932303190231323, -0.509224534034729, -0.000990644097328186, -0.5473654270172119, -0.505403459072113, -0.7390902638435364, -0.45688551664352417, 0.45295920968055725, 0.18071317672729492, 0.30715709924697876, 0.46711429953575134, -0.35194507241249084, -0.1941508650779724, -0.27751368284225464, -0.10621989518404007, -1.0711901187896729, -0.9892741441726685, 0.1611541211605072, -0.45099058747291565, -0.5078290104866028, -0.010377533733844757, 0.1593475639820099, -0.365641325712204, 0.1547805666923523, -0.30974841117858887, 0.5491448640823364, 0.1831626445055008, 0.30021002888679504, -0.6553299427032471, 0.5028278827667236, -0.22315840423107147, -0.7091383337974548, -0.5029672384262085, 0.20076268911361694, -0.5796672701835632, -0.9982079863548279, 0.8034908771514893, -0.00015279650688171387, -0.4669470191001892, -0.17963366210460663, 0.30449923872947693, -0.4559814929962158, -0.6481161713600159, -0.17948323488235474, -0.5220562815666199, -0.3927832245826721, 0.00804794393479824, 0.5105611085891724, -0.3042776882648468, 0.5108975768089294, 0.6833190321922302, 0.3389371931552887, 0.3883747458457947, 0.7094756364822388, -0.4915086627006531, 0.12218126654624939, 0.052405945956707}\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def insert_url(url):\n",
    "    res = requests.get(url)\n",
    "    content = res.text\n",
    "\n",
    "    url = \"http://localhost:11435/api/embeddings/insert_text_embeddings\"\n",
    "    data = {\n",
    "        \"source\":\"url\",\n",
    "        \"content\":content,\n",
    "        \"overlap\":50,\n",
    "        \"chunk_size\":255,\n",
    "        \"check_existing\":True,\n",
    "        \"embeddings_db\":\"EmbeddingsTest\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    print(response.text)\n",
    "\n",
    "insert_url(\"https://raw.githubusercontent.com/ollama/ollama/main/docs/api.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The API provides various functionalities such as:\n",
      "\n",
      "1. **List Models**: You can use this endpoint to retrieve a list of available models in the library.\n",
      "2. **Pull/Download Models**: This allows you to download a model from a specified name or URL, useful when using your own self-hosted instance of the API.\n",
      "3. **Push Models**: This enables you to upload a custom model to the model library. After registering for an account and getting your public key, you can use this endpoint to share your models with others.\n",
      "4. **Generate Embeddings**: Given a text prompt, you can generate embeddings using a specific model using this API endpoint. This can be used in various Natural Language Processing tasks like similarity search, recommendation systems, etc. \n",
      "\n",
      "Please note that some of these operations may require additional permissions or setup, such as registering for an account and obtaining your public key to push models.\n",
      "The API provides various functionalities such as:\n",
      "\n",
      "List Models: You can use this endpoint to retrieve a list of available models in the library.\n",
      "Pull/Download Models: This allows you to download a model from a specified name or URL, useful when using your own self-hosted instance of the API.\n",
      "Push Models: This enables you to upload a custom model to the model library. After registering for an account and getting your public key, you can use this endpoint to share your models with others.\n",
      "Generate Embeddings: Given a text prompt, you can generate embeddings using a specific model using this API endpoint. This can be used in various Natural Language Processing tasks like similarity search, recommendation systems, etc. \n",
      "\n",
      "Please note that some of these operations may require additional permissions or setup, such as registering for an account and obtaining your public key to push models.\n"
     ]
    }
   ],
   "source": [
    "#markdown render to console\n",
    "def md2print(markdown_data):\n",
    "    print(markdown_data)\n",
    "    import markdown\n",
    "    from bs4 import BeautifulSoup\n",
    "    html = markdown.markdown(markdown_data)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    print(soup.get_text())\n",
    "    return soup\n",
    "\n",
    "\n",
    "def RAG(query):\n",
    "    url = \"http://localhost:11435/api/rag\"\n",
    "    data = {\n",
    "        \"prompt\":query,\n",
    "        \"model\":\"dolphin-mistral:latest\",\n",
    "        \"related_count\":15,\n",
    "        \"max_tokens\":100,\n",
    "        \"embeddings_db\":\"EmbeddingsTest\",\n",
    "        \"temperature\":0.9\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"  \n",
    "    }\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    data= response.json()\n",
    "    md2print(data[\"message\"][\"content\"])\n",
    "\n",
    "RAG(\"what can the api do?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
